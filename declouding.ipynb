{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1668243496021,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "EcvpPRx-IVgm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST,StanfordCars\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668243250815,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "3INLn-8KC9Vq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Defining the device\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,block,layers,size):\n",
    "        self.inplanes=64\n",
    "        super(Encoder,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        self.layer1=self._make_layer(block,64,layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.layer5 = self._make_layer(block, 1024, layers[4], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(49152, size) ## CHANGE FROM HERE \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        x=self.maxpool(x)\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        x=self.layer5(x)\n",
    "        \n",
    "        x=self.avgpool(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = Encoder(Bottleneck, [3, 4, 6, 3,3,1])\n",
    "# test=torch.ones((4,3,480,720))\n",
    "# encoder(test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.dfc3=nn.Linear(size,4096)\n",
    "        self.bn3=nn.BatchNorm1d(4096)\n",
    "        self.dfc2=nn.Linear(4096,4096)\n",
    "        self.bn2=nn.BatchNorm1d(4096)\n",
    "        self.dfc1=nn.Linear(4096,256*6*6)\n",
    "        self.bn1=nn.BatchNorm1d(256*6*6)\n",
    "        self.upsample1=nn.Upsample(scale_factor=(2.648, 3))\n",
    "#         self.unflatten1 = nn.Unflatten(1, ())\n",
    "        self.dconv5 = nn.ConvTranspose2d(256, 256, 3, padding = 0)\n",
    "        self.dconv4 = nn.ConvTranspose2d(256, 384, 3, padding = 1)\n",
    "        self.dconv3 = nn.ConvTranspose2d(384, 192, 3, padding = 1)\n",
    "        self.dconv2 = nn.ConvTranspose2d(192, 64, 5, padding = 2)\n",
    "        self.dconv1 = nn.ConvTranspose2d(64, 3, 24, stride = 4, padding = (8,10))\n",
    "    def forward(self,x):\n",
    "        x = self.dfc3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        \n",
    "        x = self.dfc2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.dfc1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = x.view(-1,256,6,6)\n",
    "        x=self.upsample1(x)\n",
    "        x = self.dconv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.relu(self.dconv4(x))\n",
    "        x = F.relu(self.dconv3(x))\n",
    "        x=self.upsample1(x)\n",
    "        x = self.dconv2(x)\n",
    "        x = F.relu(x)\n",
    "        x=self.upsample1(x)\n",
    "\n",
    "        x = self.dconv1(x)\n",
    "\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tester=torch.ones((4,dims))\n",
    "# decoder=Decoder(dims)\n",
    "# (decoder(tester)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,dims):\n",
    "        super(VAE,self).__init__()\n",
    "        self.encoder = Encoder(Bottleneck, [3, 4, 6, 3,3,1],dims*2)\n",
    "        self.decoder = Decoder(dims)\n",
    "        self.dims=dims\n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.data.new(std.size()).normal_()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def forward(self,y):\n",
    "        mu_logvar = self.encoder(y)\n",
    "        mu_logvar=mu_logvar.view(-1,2,self.dims)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterise(mu, logvar).view(-1,self.dims)\n",
    "        z=self.decoder(z)\n",
    "        return z,mu,logvar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?torch.nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1668243310260,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "Vxph-StjIamO"
   },
   "outputs": [],
   "source": [
    "# # Defining the model\n",
    "\n",
    "# d = 256\n",
    "\n",
    "# class VAE(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.encoder1 = nn.Sequential(\n",
    "#             nn.Conv2d(3,4,4),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(4,1,4),\n",
    "#             nn.MaxPool2d(2),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(84609,d*2)\n",
    "#         )\n",
    "\n",
    "#         self.decoder1 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(1,8,4,stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(8,4,4,stride=1,padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(4,4,4,stride=1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "#         self.transfer=nn.Sequential(\n",
    "#             nn.Linear(d,84609),\n",
    "#             nn.Unflatten(1,(237,357))\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#     def reparameterise(self, mu, logvar):\n",
    "#         if self.training:\n",
    "#             std = logvar.mul(0.5).exp_()\n",
    "#             eps = std.data.new(std.size()).normal_()\n",
    "#             return eps.mul(std).add_(mu)\n",
    "#         else:\n",
    "#             return mu\n",
    "\n",
    "#     def forward(self, y):\n",
    "#         mu_logvar = self.encoder1(y)\n",
    "# #         print(mu_logvar.shape)\n",
    "# #         z=0\n",
    "# #         mu1=0\n",
    "# #         logvar1=0\n",
    "#         mu_logvar=mu_logvar.view(-1,2,d)\n",
    "#         mu1= mu_logvar[:, 0, :]\n",
    "#         logvar1 = mu_logvar[:, 1, :]\n",
    "#         z = self.reparameterise(mu1, logvar1).view(-1,d)\n",
    "# #         print(z.shape)\n",
    "#         z = self.transfer(z).view(-1,1,237,357)\n",
    "#         z=self.decoder1(z)\n",
    "# #         print(\"output=\",z.shape)\n",
    "#         return z,mu1,logvar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims=1024\n",
    "model = VAE(dims).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1668243325562,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "c7oyrJkTC1Pf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setting the optimiser\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668243370754,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "TMFda0HMDPtF"
   },
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "\n",
    "def loss_function(ỹ, y, mu1, logvar1):\n",
    "    BCE = nn.functional.binary_cross_entropy(\n",
    "        ỹ, y, reduction='sum'\n",
    "    )\n",
    "    KLD = (-0.5 * torch.sum(-logvar1.exp() + logvar1 + 1.0 - mu1.pow(2)))\n",
    "    return BCE + KLD,BCE,KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1668243521961,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "ejob3DR9DqOp"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, train_path):\n",
    "        self.df = pd.read_csv(train_path, sep=',', usecols=['input', 'output'])\n",
    "#         print(self.df.shape)\n",
    "    def __getitem__(self, index):\n",
    "        x = np.array(Image.open(self.df.iloc[index, 1]))\n",
    "        y = np.array(Image.open(self.df.iloc[index, 0]))\n",
    "        x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "error",
     "timestamp": 1668243568524,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "cxLMV2PJECih",
    "outputId": "c5629b81-d939-4794-d695-cfb00de301ca"
   },
   "outputs": [],
   "source": [
    "train_loader=MyDataset(\"./dataset_train.csv\")\n",
    "train_loader=DataLoader(train_loader, batch_size=2,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1668243426197,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "mDdzXB6iDayp",
    "outputId": "2123abc6-78cc-461d-9a42-113ffc96dcab"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([2, 4, 480, 720])) that is different to the input size (torch.Size([2, 3, 480, 720])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# ===================forward=====================\u001b[39;00m\n\u001b[1;32m     20\u001b[0m y_bar, mu1, logvar1 \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 21\u001b[0m loss,bc,kl \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogvar1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     23\u001b[0m bcs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mbc\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn [11], line 4\u001b[0m, in \u001b[0;36mloss_function\u001b[0;34m(ỹ, y, mu1, logvar1)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_function\u001b[39m(ỹ, y, mu1, logvar1):\n\u001b[0;32m----> 4\u001b[0m     BCE \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mỹ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     KLD \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39mlogvar1\u001b[38;5;241m.\u001b[39mexp() \u001b[38;5;241m+\u001b[39m logvar1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m mu1\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BCE \u001b[38;5;241m+\u001b[39m KLD,BCE,KLD\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3084\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3086\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3087\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3089\u001b[0m     )\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3092\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([2, 4, 480, 720])) that is different to the input size (torch.Size([2, 3, 480, 720])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "# Training and testing the VAE\n",
    "do=nn.Dropout()\n",
    "epochs = 100\n",
    "codes = dict(μ=list(), logσ2=list(), x=list())\n",
    "for epoch in range(0, epochs + 1):\n",
    "    # Training\n",
    "    if epoch > 0:  # test untrained net first\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        bcs=0\n",
    "        kls=0\n",
    "        for x,y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x=x.view(-1,3,480,720)\n",
    "            y=y.view(-1,4,480,720)\n",
    "            x=torch.div(x,255)\n",
    "            y=torch.div(y,255)\n",
    "            # ===================forward=====================\n",
    "            y_bar, mu1, logvar1 = model(x)\n",
    "            loss,bc,kl = loss_function(y_bar, y, mu1, logvar1)\n",
    "            train_loss += loss\n",
    "            bcs+=bc.item()\n",
    "            kls+=kl\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.item())\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "        print(f'====> Epoch: {epoch} Average loss: {train_loss /20000} BCE Loss: {bcs / 2000} KLD Loss: {kls / 2000}')\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    }, \"./Weights/resnet.pt\")\n",
    "        \n",
    "    # Testing\n",
    "    \n",
    "#     means, logvars, labels = list(), list(), list()\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         test_loss = 0\n",
    "#         bcs=0\n",
    "#         kls=0\n",
    "#         for y, x in test_loader:\n",
    "#             y = y.to(device)\n",
    "#             y=y.view(-1,1,28,28)\n",
    "#             # ===================forward=====================\n",
    "#             ỹ, mu1, logvar1,mu2,logvar2,mu3,logvar3 = model(y)\n",
    "#             # print(ỹ.shape)\n",
    "#             # print(y.shape)\n",
    "#             loss,bc,kl = loss_function(ỹ, y, mu1, logvar1,mu2,logvar2,mu3,logvar3)\n",
    "#             test_loss+=loss.item()\n",
    "#             bcs+=bc.item()\n",
    "#             kls+=kl.item()\n",
    "#             # =====================log=======================\n",
    "#             means.append(mu3.detach())\n",
    "#             logvars.append(logvar3.detach())\n",
    "#             labels.append(x.detach())\n",
    "#     # ===================log========================\n",
    "#     codes['μ'].append(torch.cat(means))\n",
    "#     codes['logσ2'].append(torch.cat(logvars))\n",
    "#     codes['x'].append(torch.cat(labels))\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "#     print(f'Average loss: {test_loss} BCE Loss: {bcs / len(test_loader.dataset):.4f} KLD Loss: {kls / len(test_loader.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAsyU8rHEAOC"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbAfCjL7DoeU"
   },
   "outputs": [],
   "source": [
    "test_loader=MyDataset(\"./dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp =np.array(Image.open(\"./Datasets/Input/Echendens-LHS_09620.png_6.png\"), dtype = float)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem = torch.from_numpy(temp).view(-1,3,480,720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem=tem.to(device,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=(model(tem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=(ans[0]*255).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.fromarray(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOLhjKMsR0xeixlklI73UC8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
