{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1668243496021,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "EcvpPRx-IVgm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST,StanfordCars\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "?wandb.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668243250815,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "3INLn-8KC9Vq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Defining the device\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = torch.tanh(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,block,layers,size):\n",
    "        self.inplanes=64\n",
    "        super(Encoder,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        self.layer1=self._make_layer(block,16,layers[0])\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(39168, size) ## CHANGE FROM HERE \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        x=self.maxpool(x)\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "#         x=self.layer4(x)\n",
    "        \n",
    "        x=self.avgpool(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.dfc3=nn.Linear(size,256)\n",
    "        self.bn3=nn.BatchNorm1d(256)\n",
    "        self.dfc2=nn.Linear(256,256)\n",
    "        self.bn2=nn.BatchNorm1d(256)\n",
    "        self.dfc1=nn.Linear(256,128*6*6)\n",
    "        self.bn1=nn.BatchNorm1d(4608)\n",
    "        self.upsample1=nn.Upsample(scale_factor=(2.073,2.4))\n",
    "#         self.unflatten1 = nn.Unflatten(1, ())\n",
    "        self.dconv5 = nn.ConvTranspose2d(128, 64, 3, padding = 0)\n",
    "        self.dconv4 = nn.ConvTranspose2d(64, 32, 3, padding = 1)\n",
    "        self.dconv3 = nn.ConvTranspose2d(32, 64, 3, padding = 1)\n",
    "        self.dconv2 = nn.ConvTranspose2d(64, 32, 5, padding = 2)\n",
    "        self.dconv1 = nn.ConvTranspose2d(32, 4, 24, stride = 4, padding = (10,12))\n",
    "    def forward(self,x):\n",
    "        x = self.dfc3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        \n",
    "        x = self.dfc2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.dfc1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = x.view(-1,128,6,6)\n",
    "        x=self.upsample1(x)\n",
    "        x = self.dconv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.relu(self.dconv4(x))\n",
    "        x = F.relu(self.dconv3(x))\n",
    "        x=self.upsample1(x)\n",
    "        x = self.dconv2(x)\n",
    "        x = F.relu(x)\n",
    "        x=self.upsample1(x)\n",
    "\n",
    "        x = self.dconv1(x)\n",
    "\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tester=torch.ones((4,dims))\n",
    "# decoder=Decoder(dims)\n",
    "# (decoder(tester)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,dims):\n",
    "        super(VAE,self).__init__()\n",
    "        self.encoder = Encoder(Bottleneck, [3, 4, 6, 2],dims*2)\n",
    "        self.decoder = Decoder(dims)\n",
    "        self.dims=dims\n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.data.new(std.size()).normal_()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    def forward(self,y):\n",
    "        mu_logvar = self.encoder(y)\n",
    "        mu_logvar=mu_logvar.view(-1,2,self.dims)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterise(mu, logvar).view(-1,self.dims)\n",
    "        z=self.decoder(z)\n",
    "        return z,mu,logvar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims=1024\n",
    "model = VAE(dims).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1668243325562,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "c7oyrJkTC1Pf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setting the optimiser\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668243370754,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "TMFda0HMDPtF"
   },
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "\n",
    "def loss_function(ỹ, y, mu1, logvar1):\n",
    "    BCE = nn.functional.binary_cross_entropy(\n",
    "        ỹ, y, reduction='sum'\n",
    "    )\n",
    "\n",
    "    KLD = (-0.5 * torch.mean(-logvar1.exp() + logvar1 + 1.0 - mu1.pow(2)))\n",
    "    return BCE+KLD,BCE,KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1668243521961,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "ejob3DR9DqOp"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, train_path,transform_x=None,transform_y=None):\n",
    "        self.df = pd.read_csv(train_path, sep=',', usecols=['input', 'output'])\n",
    "        self.transform_x=transform_x\n",
    "        self.transform_y=transform_y\n",
    "    def __getitem__(self, index):\n",
    "        x = np.array(Image.open(self.df.iloc[index, 1]))\n",
    "        y = np.array(Image.open(self.df.iloc[index, 0]))\n",
    "        if self.transform_x is not None:\n",
    "            x=self.transform_x(x)\n",
    "            y=self.transform_y(y)\n",
    "        else:\n",
    "            x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "#         return len(self.df)\n",
    "        return 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "  \"learning_rate\": learning_rate,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size,\n",
    "  \"dims\":dims\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpthpth\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "wandb: ERROR Failed to sample metric: Not Supported\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aryna/Documents/Sem_5/CV/AerialPoseEstimator/wandb/run-20221129_144044-3zlj5ye4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/pthpth/AerialPoseEstimator/runs/3zlj5ye4\" target=\"_blank\">balmy-breeze-40</a></strong> to <a href=\"https://wandb.ai/pthpth/AerialPoseEstimator\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pthpth/AerialPoseEstimator/runs/3zlj5ye4?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f901ed37dc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"AerialPoseEstimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "error",
     "timestamp": 1668243568524,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "cxLMV2PJECih",
    "outputId": "c5629b81-d939-4794-d695-cfb00de301ca"
   },
   "outputs": [],
   "source": [
    "train_loader=MyDataset(\"./dataset_train.csv\")\n",
    "test_loader=MyDataset(\"./dataset_test.csv\")\n",
    "train_loader=DataLoader(train_loader, batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_loader, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mean_x(loader):\n",
    "    cnt=0\n",
    "    fst_moment=torch.empty(3)\n",
    "    snd_moment=torch.empty(3)\n",
    "    for images,_ in loader:\n",
    "        # c h w b\n",
    "#         print(images.shape)\n",
    "        images=images/255\n",
    "        b,h,w,c = images.shape\n",
    "        nb_pixels=b * h * w\n",
    "        sum_ =  torch.sum(images,dim=[0,1,2])\n",
    "        sum_of_square = torch.sum(images**2,dim=[0,1,2])\n",
    "        \n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / ( cnt + nb_pixels)\n",
    "        \n",
    "        cnt+=nb_pixels\n",
    "    mean,std=fst_moment,torch.sqrt(snd_moment - fst_moment ** 2)\n",
    "    return mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mean_y(loader):\n",
    "    cnt=0\n",
    "    fst_moment=torch.empty(4)\n",
    "    snd_moment=torch.empty(4)\n",
    "    for _,images in loader:\n",
    "        # c h w b\n",
    "#         print(images.shape)\n",
    "        images=images/255\n",
    "        b,h,w,c = images.shape\n",
    "        nb_pixels=b * h * w\n",
    "        sum_ =  torch.sum(images,dim=[0,1,2])\n",
    "        sum_of_square = torch.sum(images**2,dim=[0,1,2])\n",
    "        \n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / ( cnt + nb_pixels)\n",
    "        \n",
    "        cnt+=nb_pixels\n",
    "    mean,std=fst_moment,torch.sqrt(snd_moment - fst_moment ** 2)\n",
    "    return mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x,std_x=batch_mean_x(train_loader)\n",
    "mean_y,std_y=batch_mean_y(train_loader)\n",
    "\n",
    "transform_img_normal_x = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = mean_x,std= std_x)\n",
    "])\n",
    "transform_img_normal_y = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = mean_y,std = std_y)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=MyDataset(\"./dataset_train.csv\",\n",
    "                       transform_x=transform_img_normal_x,\n",
    "                       transform_y=transform_img_normal_y)\n",
    "test_loader=MyDataset(\"./dataset_test.csv\",\n",
    "                      transform_x=transform_img_normal_x,\n",
    "                      transform_y=transform_img_normal_y)\n",
    "train_loader=DataLoader(train_loader, batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_loader, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1668243426197,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "mDdzXB6iDayp",
    "outputId": "2123abc6-78cc-461d-9a42-113ffc96dcab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m bcs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m kls\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn [14], line 7\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m----> 7\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[index, \u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/PIL/Image.py:3101\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3098\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   3099\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3101\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3103\u001b[0m preinit()\n\u001b[1;32m   3105\u001b[0m accept_warnings \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training and testing the VAE\n",
    "\n",
    "codes = dict(μ=list(), logσ2=list(), x=list())\n",
    "for epoch in range(0, epochs + 1):\n",
    "    # Training\n",
    "    if epoch > 0:  # test untrained net first\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        bcs=0\n",
    "        kls=0\n",
    "        for x,y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x=x.view(-1,3,480,720)\n",
    "            y=y.view(-1,4,480,720)\n",
    "            x=torch.div(x,255)\n",
    "            y=torch.div(y,255)\n",
    "            xs=[]\n",
    "            ys=[]\n",
    "            for i in x.split(360,-1):\n",
    "                for j in i.split(240,-2):\n",
    "                    xs.append(j)\n",
    "            for i in y.split(360,-1):\n",
    "                for j in i.split(240,-2):\n",
    "                    ys.append(j)\n",
    "            x=torch.cat(xs)\n",
    "            y=torch.cat(ys)\n",
    "            # ===================forward=====================\n",
    "            y_bar, mu1, logvar1 = model(x)\n",
    "            loss,bc,kl = loss_function(y_bar, y, mu1, logvar1)\n",
    "            train_loss += loss\n",
    "            bcs+=bc.item()\n",
    "            kls+=kl\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.item())\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "\n",
    "    # Testing\n",
    "        wandb.log({\"train_loss\":train_loss /len(train_loader.dataset), \n",
    "                       \"train BCE Loss\": bcs / len(train_loader.dataset),\n",
    "                       \"train KLD Loss\": kls / len(train_loader.dataset)})\n",
    "        means, logvars, labels = list(), list(), list()\n",
    "        if epoch%10==0:\n",
    "            torch.save({'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': train_loss,}, \n",
    "                       \"./Weights/resnet.pt\")\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        bcs=0\n",
    "        kls=0\n",
    "        for x,y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x=x.view(-1,3,480,720)\n",
    "            y=y.view(-1,4,480,720)\n",
    "            x=torch.div(x,255)\n",
    "            y=torch.div(y,255)\n",
    "            xs=[]\n",
    "            ys=[]\n",
    "            for i in x.split(360,-1):\n",
    "                for j in i.split(240,-2):\n",
    "                    xs.append(j)\n",
    "            for i in y.split(360,-1):\n",
    "                for j in i.split(240,-2):\n",
    "                    ys.append(j)\n",
    "            x=torch.cat(xs)\n",
    "            y=torch.cat(ys)\n",
    "            # ===================forward=====================\n",
    "            ỹ, mu, logvar = model(x)\n",
    "            # print(ỹ.shape)\n",
    "            # print(y.shape)\n",
    "            loss,bc,kl = loss_function(ỹ, y, mu, logvar)\n",
    "            test_loss+=loss.item()\n",
    "            bcs+=bc.item()\n",
    "            kls+=kl.item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    wandb.log({\"test_loss\":test_loss /len(test_loader.dataset), \n",
    "                   \"test BCE Loss\": bcs / len(test_loader.dataset),\n",
    "                   \"test KLD Loss\": kls / len(test_loader.dataset)})\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAsyU8rHEAOC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbAfCjL7DoeU"
   },
   "outputs": [],
   "source": [
    "# test_loader=MyDataset(\"./dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp =np.array(Image.open(\"./Datasets/Input/Echendens-LHS_09620.png_6.png\"), dtype = float)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tem = torch.from_numpy(temp).view(-1,3,480,720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tem=tem.to(device,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans=(model(tem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans=(ans[0]*255).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=Image.frtomarray(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOLhjKMsR0xeixlklI73UC8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
