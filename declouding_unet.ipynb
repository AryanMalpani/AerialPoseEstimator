{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1668243496021,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "EcvpPRx-IVgm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST,StanfordCars\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "?wandb.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668243250815,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "3INLn-8KC9Vq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Defining the device\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv2(self.relu(self.conv1(x)))\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs=(3,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "        self.pool       = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return ftrs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=(1024, 512, 256, 128, 64)):\n",
    "        super().__init__()\n",
    "        self.chs         = chs\n",
    "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
    "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
    "        \n",
    "    def forward(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)-1):\n",
    "            x        = self.upconvs[i](x)\n",
    "            enc_ftrs = self.crop(encoder_features[i], x)\n",
    "            x        = torch.cat([x, enc_ftrs], dim=1)\n",
    "            x        = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    \n",
    "    def crop(self, enc_ftrs, x):\n",
    "        _, _, H, W = x.shape\n",
    "        enc_ftrs   = torchvision.transforms.CenterCrop([H, W])(enc_ftrs)\n",
    "        return enc_ftrs\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, enc_chs=(3,64,128,256,512,1024), dec_chs=(1024, 512, 256, 128, 64), num_class=1, retain_dim=False, out_sz=(572,572)):\n",
    "        super().__init__()\n",
    "        self.encoder     = Encoder(enc_chs)\n",
    "        self.decoder     = Decoder(dec_chs)\n",
    "        self.head        = nn.Conv2d(dec_chs[-1], num_class, 1)\n",
    "        self.retain_dim  = retain_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_ftrs = self.encoder(x)\n",
    "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
    "        out      = self.head(out)\n",
    "        if self.retain_dim:\n",
    "            out = F.interpolate(out, out_sz)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dims=1024\n",
    "# model = VAE(dims).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1668243325562,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "c7oyrJkTC1Pf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setting the optimiser\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668243370754,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "TMFda0HMDPtF"
   },
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "\n",
    "def loss_function(ỹ, y):\n",
    "    BCE = nn.functional.binary_cross_entropy(\n",
    "        ỹ, y, reduction='sum'\n",
    "    )\n",
    "#     KLD = (-0.5 * torch.mean(-logvar1.exp() + logvar1 + 1.0 - mu1.pow(2)))\n",
    "    return BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1668243521961,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "ejob3DR9DqOp"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, train_path,transform_x=None,transform_y=None):\n",
    "        self.df = pd.read_csv(train_path, sep=',', usecols=['input', 'output'])\n",
    "        self.transform_x=transform_x\n",
    "        self.transform_y=transform_y\n",
    "    def __getitem__(self, index):\n",
    "#         print(self.df.iloc[index, 1])\n",
    "#         print(self.df.iloc[index, 0])\n",
    "        x = np.array(Image.open(self.df.iloc[index, 1]))\n",
    "        y = np.array(Image.open(self.df.iloc[index, 0]))\n",
    "        if self.transform_x is not None:\n",
    "            x=self.transform_x(x)\n",
    "            y=self.transform_y(y)\n",
    "        else:\n",
    "            x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "#         return len(self.df)\n",
    "        return 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "  \"learning_rate\": learning_rate,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size,\n",
    "  \"dims\":dims\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpthpth\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "wandb: ERROR Failed to sample metric: Not Supported\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aryna/Documents/Sem_5/CV/AerialPoseEstimator/wandb/run-20221209_040016-3mytavta</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/pthpth/AerialPoseEstimator/runs/3mytavta\" target=\"_blank\">fast-spaceship-54</a></strong> to <a href=\"https://wandb.ai/pthpth/AerialPoseEstimator\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pthpth/AerialPoseEstimator/runs/3mytavta?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f88b40b99d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"AerialPoseEstimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "error",
     "timestamp": 1668243568524,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "cxLMV2PJECih",
    "outputId": "c5629b81-d939-4794-d695-cfb00de301ca"
   },
   "outputs": [],
   "source": [
    "train_loader=MyDataset(\"./dataset_train.csv\")\n",
    "test_loader=MyDataset(\"./dataset_test.csv\")\n",
    "train_loader=DataLoader(train_loader, batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_loader, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mean_x(loader):\n",
    "    cnt=0\n",
    "    fst_moment=torch.empty(3)\n",
    "    snd_moment=torch.empty(3)\n",
    "    for images,_ in loader:\n",
    "        # c h w b\n",
    "#         print(images.shape)\n",
    "        images=images/255\n",
    "        b,h,w,c = images.shape\n",
    "        nb_pixels=b * h * w\n",
    "        sum_ =  torch.sum(images,dim=[0,1,2])\n",
    "        sum_of_square = torch.sum(images**2,dim=[0,1,2])\n",
    "        \n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / ( cnt + nb_pixels)\n",
    "        \n",
    "        cnt+=nb_pixels\n",
    "    mean,std=fst_moment,torch.sqrt(snd_moment - fst_moment ** 2)\n",
    "    return mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mean_y(loader):\n",
    "    cnt=0\n",
    "    fst_moment=torch.empty(4)\n",
    "    snd_moment=torch.empty(4)\n",
    "    for _,images in loader:\n",
    "        # c h w b\n",
    "#         print(images.shape)\n",
    "        images=images/255\n",
    "        b,h,w,c = images.shape\n",
    "        nb_pixels=b * h * w\n",
    "        sum_ =  torch.sum(images,dim=[0,1,2])\n",
    "        sum_of_square = torch.sum(images**2,dim=[0,1,2])\n",
    "        \n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / ( cnt + nb_pixels)\n",
    "        \n",
    "        cnt+=nb_pixels\n",
    "    mean,std=fst_moment,torch.sqrt(snd_moment - fst_moment ** 2)\n",
    "    return mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x,std_x=batch_mean_x(train_loader)\n",
    "mean_y,std_y=batch_mean_y(train_loader)\n",
    "\n",
    "transform_img_normal_x = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = mean_x,std= std_x)\n",
    "])\n",
    "transform_img_normal_y = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = 0,std = 1)\n",
    "])\n",
    "train_loader=MyDataset(\"./dataset_train.csv\",\n",
    "                       transform_x=transform_img_normal_x,\n",
    "                       transform_y=transform_img_normal_y)\n",
    "test_loader=MyDataset(\"./dataset_test.csv\",\n",
    "                      transform_x=transform_img_normal_x,\n",
    "                      transform_y=transform_img_normal_y)\n",
    "train_loader=DataLoader(train_loader, batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_loader, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1668243426197,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "mDdzXB6iDayp",
    "outputId": "2123abc6-78cc-461d-9a42-113ffc96dcab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# Training and testing the VAE\n",
    "\n",
    "codes = dict(μ=list(), logσ2=list(), x=list())\n",
    "for epoch in range(0, epochs + 1):\n",
    "    # Training\n",
    "    if epoch > 0:  # test untrained net first\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        bcs=0\n",
    "        kls=0\n",
    "        for x,y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x=x.view(-1,3,480,720)\n",
    "            y=y.view(-1,4,480,720)\n",
    "            x=torch.div(x,255)\n",
    "            y=torch.div(y,255)\n",
    "            xs=[]\n",
    "            ys=[]\n",
    "            for i in x.split(360,-1):\n",
    "                for j in i.split(240,-2):\n",
    "                    xs.append(j)\n",
    "            for i in y.split(360,-1):\n",
    "                for j in i.split(240,-2):\n",
    "                    ys.append(j)\n",
    "            x=torch.cat(xs)\n",
    "            y=torch.cat(ys)\n",
    "            # ===================forward=====================\n",
    "#             y_bar, mu1, logvar1 = model(x)\n",
    "#             loss,bc,kl = loss_function(y_bar, y, mu1, logvar1)\n",
    "            y_bar=model(x)\n",
    "            loss = loss_function(y_bar, y)\n",
    "            train_loss += loss\n",
    "#             bcs+=bc.item()\n",
    "#             kls+=kl\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.item())\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "\n",
    "    # Testing\n",
    "        wandb.log({\"train_loss\":train_loss /len(train_loader.dataset), \n",
    "                       \"train BCE Loss\": bcs / len(train_loader.dataset),\n",
    "                       \"train KLD Loss\": kls / len(train_loader.dataset)})\n",
    "        means, logvars, labels = list(), list(), list()\n",
    "        if epoch%10==0:\n",
    "            torch.save({'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': train_loss,}, \n",
    "                       \"./Weights/resnet.pt\")\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        bcs=0\n",
    "        kls=0\n",
    "        for x,y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x=x.view(-1,3,480,720)\n",
    "            y=y.view(-1,4,480,720)\n",
    "            x=torch.div(x,255)\n",
    "            y=torch.div(y,255)\n",
    "            xs=[]\n",
    "            ys=[]\n",
    "            for i in x.split(360,-1):\n",
    "                for j in i.split(240,-2):\n",
    "                    xs.append(j)\n",
    "            for i in y.split(360,-1):\n",
    "                for j in i.split(240,-2):\n",
    "                    ys.append(j)\n",
    "            x=torch.cat(xs)\n",
    "            y=torch.cat(ys)\n",
    "            # ===================forward=====================\n",
    "#             ỹ, mu, logvar = model(x)\n",
    "            ỹ = model(x)\n",
    "            # print(ỹ.shape)\n",
    "            # print(y.shape)\n",
    "#             loss,bc,kl = loss_function(ỹ, y, mu, logvar)\n",
    "            loss = loss_function(ỹ, y)\n",
    "            test_loss+=loss.item()\n",
    "#             bcs+=bc.item()\n",
    "#             kls+=kl.item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    wandb.log({\"test_loss\":test_loss /len(test_loader.dataset), \n",
    "                   \"test BCE Loss\": bcs / len(test_loader.dataset),\n",
    "                   \"test KLD Loss\": kls / len(test_loader.dataset)})\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAsyU8rHEAOC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbAfCjL7DoeU"
   },
   "outputs": [],
   "source": [
    "# test_loader=MyDataset(\"./dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp =np.array(Image.open(\"./Datasets/Input/Echendens-LHS_09620.png_6.png\"), dtype = float)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tem = torch.from_numpy(temp).view(-1,3,480,720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tem=tem.to(device,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans=(model(tem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans=(ans[0]*255).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=Image.frtomarray(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOLhjKMsR0xeixlklI73UC8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
