{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1668243496021,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "EcvpPRx-IVgm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST,StanfordCars\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: wandb.init: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!wandb.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668243250815,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "3INLn-8KC9Vq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Defining the device\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_res_block(tiny, num_gn_channel, ch_down_factor=1):\n",
    "    \"\"\"Create residual block\"\"\"\n",
    "    num_ch = (512, 128)[tiny] // ch_down_factor\n",
    "    res_block = nn.Sequential(nn.Conv2d(num_ch, num_ch, 3, 1, 1),\n",
    "                              nn.GroupNorm(min(num_gn_channel, num_ch), num_ch),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Conv2d(num_ch, num_ch, 1, 1, 0),\n",
    "                              nn.GroupNorm(min(num_gn_channel, num_ch), num_ch),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Conv2d(num_ch, num_ch, 3, 1, 1),\n",
    "                              nn.GroupNorm(min(num_gn_channel, num_ch), num_ch),\n",
    "                              nn.ReLU()\n",
    "                              )\n",
    "    return res_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,tiny,enc_add_res_block=0,num_gn_channel=32):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.tiny=tiny\n",
    "        self.enc=enc_add_res_block\n",
    "        self.gn_channel=num_gn_channel\n",
    "        self.num_gn_channel = num_gn_channel\n",
    "        self.conv1 = nn.Conv2d(3, num_gn_channel, 3, 1, 1)\n",
    "        self.norm1 = nn.GroupNorm(num_gn_channel, num_gn_channel)\n",
    "        self.conv2 = nn.Conv2d(num_gn_channel, 64, 3, 2, 1)\n",
    "        self.norm2 = nn.GroupNorm(num_gn_channel, 64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 2, 1)\n",
    "        self.norm3 = nn.GroupNorm(num_gn_channel, 128)\n",
    "        self.conv4 = nn.Conv2d(128, (256, 128)[tiny], 3, 2, 1)\n",
    "        self.norm4 = nn.GroupNorm(num_gn_channel, (256, 128)[tiny])\n",
    "\n",
    "        self.res1_conv1 = nn.Conv2d((256, 128)[tiny], (256, 128)[tiny], 3, 1, 1)\n",
    "        self.res1_norm1 = nn.GroupNorm(num_gn_channel, (256, 128)[tiny])\n",
    "        self.res1_conv2 = nn.Conv2d((256, 128)[tiny], (256, 128)[tiny], 1, 1, 0)\n",
    "        self.res1_norm2 = nn.GroupNorm(num_gn_channel, (256, 128)[tiny])\n",
    "        self.res1_conv3 = nn.Conv2d((256, 128)[tiny], (256, 128)[tiny], 3, 1, 1)\n",
    "        self.res1_norm3 = nn.GroupNorm(num_gn_channel, (256, 128)[tiny])\n",
    "\n",
    "        self.res2_conv1 = nn.Conv2d((256, 128)[tiny], (512, 128)[tiny], 3, 1, 1)\n",
    "        self.res2_norm1 = nn.GroupNorm(num_gn_channel, (512, 128)[tiny])\n",
    "        self.res2_conv2 = nn.Conv2d((512, 128)[tiny], (512, 128)[tiny], 1, 1, 0)\n",
    "        self.res2_norm2 = nn.GroupNorm(num_gn_channel, (512, 128)[tiny])\n",
    "        self.res2_conv3 = nn.Conv2d((512, 128)[tiny], (512, 128)[tiny], 3, 1, 1)\n",
    "        self.res2_norm3 = nn.GroupNorm(num_gn_channel, (512, 128)[tiny])\n",
    "\n",
    "        if not tiny:\n",
    "            self.res2_skip = nn.Conv2d(256, 512, 1, 1, 0)\n",
    "            self.res2_skip_norm = nn.GroupNorm(num_gn_channel, 512)\n",
    "        self.enc_add_res_block_ls = [_create_res_block(tiny, num_gn_channel) for _ in range(enc_add_res_block)]\n",
    "        for i, block in enumerate(self.enc_add_res_block_ls):\n",
    "            self.add_module('enc_add_res_block{:d}'.format(i+1), block)\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = F.relu(self.norm1(self.conv1(x)))\n",
    "        x = F.relu(self.norm2(self.conv2(x)))\n",
    "        x = F.relu(self.norm3(self.conv3(x)))\n",
    "        res = F.relu(self.norm4(self.conv4(x)))\n",
    "\n",
    "        x = F.relu(self.res1_norm1(self.res1_conv1(res)))\n",
    "        x = F.relu(self.res1_norm2(self.res1_conv2(x)))\n",
    "        x = F.relu(self.res1_norm3(self.res1_conv3(x)))\n",
    "\n",
    "        res = F.relu(res + x)\n",
    "\n",
    "        x = F.relu(self.res2_norm1(self.res2_conv1(res)))\n",
    "        x = F.relu(self.res2_norm2(self.res2_conv2(x)))\n",
    "        x = F.relu(self.res2_norm3(self.res2_conv3(x)))\n",
    "\n",
    "        if not self.tiny:\n",
    "            res = self.res2_skip_norm(self.res2_skip(res))\n",
    "\n",
    "        res = F.relu(res + x)\n",
    "\n",
    "        # additional residual block\n",
    "        for i in range(len(self.enc_add_res_block_ls)):\n",
    "            x = self.enc_add_res_block_ls[i](res)\n",
    "            res = F.relu(res + x)\n",
    "\n",
    "        return res\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseUpsamplingConvolution(nn.Module):\n",
    "    def __init__(self, down_sampling_rate, in_channel, num_classes, num_gn_channel=32):\n",
    "        super(DenseUpsamplingConvolution, self).__init__()\n",
    "        up_sampling_channel = (down_sampling_rate ** 2) * num_classes\n",
    "        self.conv = nn.Conv2d(in_channel, up_sampling_channel, 3, 1, 1)\n",
    "        self.norm = nn.GroupNorm(num_gn_channel, up_sampling_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(down_sampling_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.norm(self.conv(x)))\n",
    "        x = self.pixel_shuffle(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"A modular decoder for TransPose network.\"\"\"\n",
    "    def __init__(self, tiny, dec_add_res_block=0, num_gn_channel=32, full_size_output=False):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # learned output relative to its mean (e.g. center of the scene)\n",
    "        self.tiny = tiny\n",
    "        self.dec_add_res_block = dec_add_res_block\n",
    "        self.num_gn_channel = num_gn_channel\n",
    "        self.full_size_output = full_size_output\n",
    "\n",
    "        # Additional residual block could be added on top of the vanilla decoder.\n",
    "        self.dec_add_res_block_ls = [_create_res_block(tiny, num_gn_channel) for _ in range(dec_add_res_block)]\n",
    "        for i, block in enumerate(self.dec_add_res_block_ls):\n",
    "            self.add_module('dec_add_res_block{:d}'.format(i+1), block)\n",
    "\n",
    "        self.res3_conv1 = nn.Conv2d((512, 128)[tiny], (512, 128)[tiny], 1, 1, 0)\n",
    "        self.res3_norm1 = nn.GroupNorm(num_gn_channel, (512, 128)[tiny])\n",
    "        self.res3_conv2 = nn.Conv2d((512, 128)[tiny], (512, 128)[tiny], 1, 1, 0)\n",
    "        self.res3_norm2 = nn.GroupNorm(num_gn_channel, (512, 128)[tiny])\n",
    "        self.res3_conv3 = nn.Conv2d((512, 128)[tiny], (512, 128)[tiny], 1, 1, 0)\n",
    "        self.res3_norm3 = nn.GroupNorm(num_gn_channel, (512, 128)[tiny])\n",
    "\n",
    "        self.fc1 = nn.Conv2d((512, 128)[tiny], (512, 128)[tiny], 1, 1, 0)\n",
    "        self.fc1_norm = nn.GroupNorm(min((512, 128)[tiny], num_gn_channel), (512, 128)[tiny])\n",
    "        self.fc2 = nn.Conv2d((512, 128)[tiny], (512, 128)[tiny], 1, 1, 0)\n",
    "        self.fc2_norm = nn.GroupNorm(min((512, 128)[tiny], num_gn_channel), (512, 128)[tiny])\n",
    "        if full_size_output:\n",
    "            # upsampling for semantics task\n",
    "            self.duc_upsample = DenseUpsamplingConvolution(down_sampling_rate=8, in_channel=(512, 128)[tiny],\n",
    "                                                           num_classes=4)\n",
    "            self.fc3 = nn.Conv2d(4, 4, 1, 1, 0)\n",
    "        else:\n",
    "            self.fc3 = nn.Conv2d((512, 128)[tiny], 4, 1, 1, 0)\n",
    "\n",
    "    def forward(self, inputs, up_height=None, up_width=None):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        @param inputs           4D data tensor (BxCxHxW)\n",
    "        @param up_height        Scalar, up-sampling target tensor height\n",
    "        @param up_width         Scalar, up-sampling target tensor width\n",
    "        \"\"\"\n",
    "\n",
    "        res = inputs\n",
    "\n",
    "        # additional residual block\n",
    "        # self.dec_add_res_block_ls[0][0] or self.res3_conv1 layer input is the intermediate activation [feature vec.].\n",
    "        for i in range(len(self.dec_add_res_block_ls)):\n",
    "            x = self.dec_add_res_block_ls[i](res)\n",
    "            res = F.relu(res + x)\n",
    "\n",
    "        x = F.relu(self.res3_norm1(self.res3_conv1(res)))\n",
    "        x = F.relu(self.res3_norm2(self.res3_conv2(x)))\n",
    "        x = F.relu(self.res3_norm3(self.res3_conv3(x)))\n",
    "\n",
    "        res = F.relu(res + x)\n",
    "\n",
    "        sc = F.relu(self.fc1_norm(self.fc1(res)))\n",
    "        sc = F.relu(self.fc2_norm(self.fc2(sc)))\n",
    "        if self.full_size_output:\n",
    "            # upsampling for semantics task\n",
    "            sc = self.duc_upsample(sc)  # [B, C, H', W']\n",
    "            sc = F.interpolate(sc, (up_height, up_width), mode='bilinear', align_corners=False)  # trim dimensions\n",
    "\n",
    "        sc = self.fc3(sc)\n",
    "        sc=F.sigmoid(sc)\n",
    "        return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_mlr_concatenator(num_mlr, tiny, num_gn_channel):\n",
    "    \"\"\"Create activation concatenation block for MLR.\"\"\"\n",
    "    in_channel = (512, 128)[tiny] * num_mlr\n",
    "    out_channel = (512, 128)[tiny]\n",
    "    mlr_block = nn.Sequential(nn.Conv2d(in_channel, out_channel, 3, 1, 1),\n",
    "                              nn.GroupNorm(num_gn_channel, out_channel),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Conv2d(out_channel, out_channel, 1, 1, 0),\n",
    "                              nn.GroupNorm(num_gn_channel, out_channel),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Conv2d(out_channel, out_channel, 3, 1, 1),\n",
    "                              nn.GroupNorm(num_gn_channel, out_channel),\n",
    "                              nn.ReLU()\n",
    "                              )\n",
    "    return mlr_block\n",
    "\n",
    "\n",
    "def _create_mlr_skip_layer(num_mlr, tiny, num_gn_channel):\n",
    "    \"\"\"Create skip layer for MLR\"\"\"\n",
    "    in_channel = (512, 128)[tiny] * num_mlr\n",
    "    out_channel = (512, 128)[tiny]\n",
    "    skip_block = nn.Sequential(nn.Conv2d(in_channel, out_channel, 1, 1, 0),\n",
    "                               nn.GroupNorm(num_gn_channel, out_channel))\n",
    "    return skip_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Flexible FCN architecture for various regression tasks.\n",
    "    The output is sub-sampled by a factor of 8 compared to the image input.\n",
    "    Contents of changes:\n",
    "    - Added non-grayscale RGB image input.\n",
    "    - Added group normalization.\n",
    "    - Added encoder/decoder separation and supported an arbitrary number of residual blocks.\n",
    "    - Added support for arbitrary-channel regression task output and positive-value uncertainty output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,tiny, enc_add_res_block=0, dec_add_res_block=0,num_gn_channel=32,\n",
    "                 num_mlr=0, num_unfrozen_encoder=0, full_size_output=False):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "        @param mean                 Mean offset for task output.\n",
    "        @param tiny                 Flag for tiny network.\n",
    "        @param grayscale            Flag for grayscale image input.\n",
    "        @param enc_add_res_block    Number of additional DSAC* style residual block for encoder.\n",
    "        @param dec_add_res_block    Number of additional DSAC* style residual block for decoder.\n",
    "        @param num_task_channel     Number of channels for underlying task.\n",
    "        @param num_pos_channel      Number of channels for additional task w/ positive values, e.g., uncertainty.\n",
    "        @param num_gn_channel       Number of group normalization channels, a hyper-parameter.\n",
    "        @param num_mlr              Number of homogeneous mid-level representations encoders.\n",
    "        @param num_unfrozen_encoder Number of encoders that are not frozen.\n",
    "        @param full_size_output     Flag for full-size network output (by using DUC-style layers).\n",
    "        Note: if enc_add_res_block == dec_add_res_block == 0 && num_task_channel == 3 && num_pos_channel = 0,\n",
    "        the model become DSAC* net + group normalization only.\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        \"\"\"Init\"\"\"\n",
    "        # learned output relative to its mean (e.g. center of the scene)\n",
    "        self.tiny = tiny\n",
    "        self.enc_add_res_block = enc_add_res_block\n",
    "        self.dec_add_res_block = dec_add_res_block\n",
    "        self.num_gn_channel = num_gn_channel\n",
    "        self.num_mlr = num_mlr\n",
    "        self.full_size_output = full_size_output\n",
    "\n",
    "        self.OUTPUT_SUBSAMPLE = 1 if full_size_output else 8\n",
    "\n",
    "        \"\"\"Vanilla encoder\"\"\"\n",
    "        if num_mlr == 0:\n",
    "            self.encoder = Encoder(tiny,enc_add_res_block, num_gn_channel)\n",
    "            self.encoder_ls = [self.encoder]\n",
    "        else:\n",
    "            self.encoder = nn.Identity()\n",
    "            self.encoder_ls = [self.encoder]\n",
    "\n",
    "        \"\"\"MLR encoders\"\"\"\n",
    "        if num_mlr > 0 and isinstance(num_mlr, int):\n",
    "            assert 0 <= num_unfrozen_encoder <= num_mlr\n",
    "            self.mlr_encoder_ls = [Encoder(tiny, enc_add_res_block, num_gn_channel) for _ in range(num_mlr)]\n",
    "            # Freeze gradients of the re-used encoder\n",
    "            for i, block in enumerate(self.mlr_encoder_ls):\n",
    "                if i >= num_unfrozen_encoder:  # the first few encoders **may** be reused for training\n",
    "                    for param in block.parameters():\n",
    "                        param.requires_grad = False\n",
    "                self.add_module('mlr_encoder_{:d}'.format(i + 1), block)\n",
    "            self.mlr_norm = nn.GroupNorm(num_gn_channel, (512, 128)[tiny] * num_mlr)\n",
    "            self.mlr_forward = _create_mlr_concatenator(num_mlr, tiny, num_gn_channel)\n",
    "            self.mlr_skip = _create_mlr_skip_layer(num_mlr, tiny, num_gn_channel)  # normalization is included\n",
    "        else:\n",
    "            self.mlr_encoder_ls = [nn.Identity()]\n",
    "            self.mlr_norm = nn.Identity()\n",
    "            self.mlr_forward = nn.Identity()\n",
    "            self.mlr_skip = nn.Identity()\n",
    "        self.mlr_ls = self.mlr_encoder_ls + [self.mlr_norm, self.mlr_forward, self.mlr_skip]\n",
    "\n",
    "        \"\"\"Decoder\"\"\"\n",
    "        # we always have a decoder regardless of the #MLR\n",
    "        self.decoder = Decoder(tiny, dec_add_res_block, num_gn_channel, full_size_output)\n",
    "        self.decoder_ls = [self.decoder]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        @param inputs           4D data tensor (BxCxHxW)\n",
    "        \"\"\"\n",
    "\n",
    "        x = inputs\n",
    "        up_height, up_width = inputs.size()[2:4]\n",
    "\n",
    "        \"\"\"Vanilla encoder\"\"\"\n",
    "        if self.num_mlr == 0:\n",
    "            res = self.encoder(x)\n",
    "        else:\n",
    "            res = None\n",
    "\n",
    "        \"\"\"MLR encoder\"\"\"\n",
    "        if self.num_mlr:\n",
    "            # inference\n",
    "            mlr_activation_ls = [mlr_enc(inputs) for mlr_enc in self.mlr_encoder_ls]\n",
    "\n",
    "            # activation concatenation\n",
    "            mlr = torch.cat(mlr_activation_ls, dim=1)  # [B, C * #MLR, H, W]\n",
    "\n",
    "            # forward\n",
    "            res = self.mlr_skip(mlr)\n",
    "            mlr = self.mlr_norm(mlr)\n",
    "            mlr = self.mlr_forward(mlr)\n",
    "            res = F.relu(res + mlr)\n",
    "\n",
    "        \"\"\"Decoder\"\"\"\n",
    "        if self.full_size_output:\n",
    "            sc = self.decoder(res, up_height, up_width)\n",
    "        else:\n",
    "            sc = self.decoder(res)\n",
    "\n",
    "        return sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net(tiny=1,enc_add_res_block=3,dec_add_res_block=3,num_gn_channel=32,num_mlr=2,num_unfrozen_encoder=2,full_size_output=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1668243325562,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "c7oyrJkTC1Pf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setting the optimiser\n",
    "\n",
    "learning_rate = 1e-3*5\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668243370754,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "TMFda0HMDPtF"
   },
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "\n",
    "def loss_function(ỹ, y):\n",
    "    BCE = nn.functional.binary_cross_entropy(\n",
    "        ỹ, y,reduction='sum'\n",
    "    )\n",
    "#     KLD = (-0.5 * torch.mean(-logvar1.exp() + logvar1 + 1.0 - mu1.pow(2)))\n",
    "    return BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1668243521961,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "ejob3DR9DqOp"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, train_path,transform_x=None,transform_y=None):\n",
    "        self.df = pd.read_csv(train_path, sep=',', usecols=['input', 'output'])\n",
    "        self.transform_x=transform_x\n",
    "        self.transform_y=transform_y\n",
    "    def __getitem__(self, index):\n",
    "#         print(self.df.iloc[index, 1])\n",
    "#         print(self.df.iloc[index, 0])\n",
    "        x = Image.open(self.df.iloc[index, 1])\n",
    "        y = Image.open(self.df.iloc[index, 0])\n",
    "        if self.transform_x is not None:\n",
    "            x=self.transform_x(x)\n",
    "            y=self.transform_y(y)\n",
    "        else:\n",
    "            x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "#         return len(self.df)\n",
    "        return 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_np(Dataset):\n",
    "    def __init__(self, train_path,transform_x=None,transform_y=None):\n",
    "        self.df = pd.read_csv(train_path, sep=',', usecols=['input', 'output'])\n",
    "        self.transform_x=transform_x\n",
    "        self.transform_y=transform_y\n",
    "    def __getitem__(self, index):\n",
    "#         print(self.df.iloc[index, 1])\n",
    "#         print(self.df.iloc[index, 0])\n",
    "        x = np.array(Image.open(self.df.iloc[index, 1]))\n",
    "        y = np.array(Image.open(self.df.iloc[index, 0]))\n",
    "        if self.transform_x is not None:\n",
    "            x=self.transform_x(x)\n",
    "            y=self.transform_y(y)\n",
    "        else:\n",
    "            x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "#         return len(self.df)\n",
    "        return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "  \"learning_rate\": learning_rate,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpthpth\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "wandb: ERROR Failed to sample metric: Not Supported\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aryna/Documents/Sem_5/CV/AerialPoseEstimator/wandb/run-20221211_064248-3zxn0zes</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/pthpth/AerialPoseEstimator/runs/3zxn0zes\" target=\"_blank\">quiet-galaxy-90</a></strong> to <a href=\"https://wandb.ai/pthpth/AerialPoseEstimator\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pthpth/AerialPoseEstimator/runs/3zxn0zes?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1019f48a00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"AerialPoseEstimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "error",
     "timestamp": 1668243568524,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "cxLMV2PJECih",
    "outputId": "c5629b81-d939-4794-d695-cfb00de301ca"
   },
   "outputs": [],
   "source": [
    "train_loader=MyDataset_np(\"./dataset_train.csv\")\n",
    "test_loader=MyDataset_np(\"./dataset_test.csv\")\n",
    "train_loader=DataLoader(train_loader, batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_loader, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mean_x(loader):\n",
    "    cnt=0\n",
    "    fst_moment=torch.empty(3)\n",
    "    snd_moment=torch.empty(3)\n",
    "    for images,_ in loader:\n",
    "        # c h w b\n",
    "#         print(images.shape)\n",
    "        images=images/255\n",
    "        b,h,w,c = images.shape\n",
    "        nb_pixels=b * h * w\n",
    "        sum_ =  torch.sum(images,dim=[0,1,2])\n",
    "        sum_of_square = torch.sum(images**2,dim=[0,1,2])\n",
    "        \n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / ( cnt + nb_pixels)\n",
    "        \n",
    "        cnt+=nb_pixels\n",
    "    mean,std=fst_moment,torch.sqrt(snd_moment - fst_moment ** 2)\n",
    "    return mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mean_y(loader):\n",
    "    cnt=0\n",
    "    fst_moment=torch.empty(4)\n",
    "    snd_moment=torch.empty(4)\n",
    "    for _,images in loader:\n",
    "        images=images/255\n",
    "        b,h,w,c = images.shape\n",
    "        nb_pixels=b * h * w\n",
    "        sum_ =  torch.sum(images,dim=[0,1,2])\n",
    "        sum_of_square = torch.sum(images**2,dim=[0,1,2])\n",
    "        \n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / ( cnt + nb_pixels)\n",
    "        \n",
    "        cnt+=nb_pixels\n",
    "    mean,std=fst_moment,torch.sqrt(snd_moment - fst_moment ** 2)\n",
    "    return mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x,std_x=batch_mean_x(train_loader)\n",
    "mean_y,std_y=batch_mean_y(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=MyDataset(\"./dataset_train.csv\")\n",
    "test_loader=MyDataset(\"./dataset_test.csv\")\n",
    "train_loader=DataLoader(train_loader, batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_loader, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_img_normal_x = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = mean_x,std= std_x)\n",
    "])\n",
    "transform_img_normal_y = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_loader=MyDataset(\"./dataset_train.csv\",\n",
    "                       transform_x=transform_img_normal_x,\n",
    "                       transform_y=transform_img_normal_y)\n",
    "test_loader=MyDataset(\"./dataset_test.csv\",\n",
    "                      transform_x=transform_img_normal_x,\n",
    "                      transform_y=transform_img_normal_y)\n",
    "train_loader=DataLoader(train_loader, batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test_loader, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1668243426197,
     "user": {
      "displayName": "Parth Tulsyan",
      "userId": "14552357153811248538"
     },
     "user_tz": -330
    },
    "id": "mDdzXB6iDayp",
    "outputId": "2123abc6-78cc-461d-9a42-113ffc96dcab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryna/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955933.273\n",
      "0\n",
      "tensor(2.8413e+08, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29237.6069765625\n",
      "1\n",
      "tensor(23568126., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21651.368578125\n",
      "2\n",
      "tensor(21438002., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21201.5213125\n",
      "3\n",
      "tensor(21192146., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21078.0229921875\n",
      "4\n",
      "tensor(21107540., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21020.3495078125\n",
      "5\n",
      "tensor(21074516., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21001.7000703125\n",
      "6\n",
      "tensor(21058938., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20991.0094296875\n",
      "7\n",
      "tensor(21050544., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20983.88371875\n",
      "8\n",
      "tensor(21044216., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20976.95228125\n",
      "9\n",
      "tensor(21040036., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20972.3547109375\n",
      "10\n",
      "tensor(21036496., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20969.3505390625\n",
      "11\n",
      "tensor(21029996., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20962.6345625\n",
      "12\n",
      "tensor(21025220., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20957.337609375\n",
      "13\n",
      "tensor(21021056., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20954.1751171875\n",
      "14\n",
      "tensor(21017652., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20952.6945234375\n",
      "15\n",
      "tensor(21016284., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20950.95546875\n",
      "16\n",
      "tensor(21014382., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20947.6627421875\n",
      "17\n",
      "tensor(21011926., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20945.7111328125\n",
      "18\n",
      "tensor(21011194., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20948.957125\n",
      "19\n",
      "tensor(21009918., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20942.4150546875\n",
      "20\n",
      "tensor(21031408., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20948.443265625\n",
      "21\n",
      "tensor(21011358., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20944.61190625\n",
      "22\n",
      "tensor(21009552., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20948.0152734375\n",
      "23\n",
      "tensor(21009030., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20944.0645625\n",
      "24\n",
      "tensor(21008288., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20941.4654609375\n",
      "25\n",
      "tensor(21007428., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20941.3174921875\n",
      "26\n",
      "tensor(21006736., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20940.36159375\n",
      "27\n",
      "tensor(21006520., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20939.431015625\n",
      "28\n",
      "tensor(21005320., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20939.4308515625\n",
      "29\n",
      "tensor(21004326., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20937.7785\n",
      "30\n",
      "tensor(21004854., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20938.495234375\n",
      "31\n",
      "tensor(21003498., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20936.024875\n",
      "32\n",
      "tensor(21002926., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20936.9959453125\n",
      "33\n",
      "tensor(21002854., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20937.5485703125\n",
      "34\n",
      "tensor(21003120., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20939.6060859375\n",
      "35\n",
      "tensor(20999620., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20930.389171875\n",
      "36\n",
      "tensor(20998950., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20931.448515625\n",
      "37\n",
      "tensor(20996792., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20928.986640625\n",
      "38\n",
      "tensor(20995698., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20927.4964375\n",
      "39\n",
      "tensor(20994604., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20925.628265625\n",
      "40\n",
      "tensor(20993740., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20926.801515625\n",
      "41\n",
      "tensor(20993038., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20930.0403046875\n",
      "42\n",
      "tensor(20990954., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20923.3978515625\n",
      "43\n",
      "tensor(20992194., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20925.1181875\n",
      "44\n",
      "tensor(20990550., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20923.155421875\n",
      "45\n",
      "tensor(20989694., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20920.77596875\n",
      "46\n",
      "tensor(20987536., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20925.8417890625\n",
      "47\n",
      "tensor(20988566., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20925.4467265625\n",
      "48\n",
      "tensor(20985654., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20918.43259375\n",
      "49\n",
      "tensor(20985418., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20917.2486875\n",
      "50\n",
      "tensor(20985544., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20920.5076484375\n",
      "51\n",
      "tensor(20984584., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20919.6528515625\n",
      "52\n",
      "tensor(20985540., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20917.01403125\n",
      "53\n",
      "tensor(20983314., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20916.5244296875\n",
      "54\n",
      "tensor(20983570., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20915.0756953125\n",
      "55\n",
      "tensor(20983596., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20916.780125\n",
      "56\n",
      "tensor(20983314., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20914.4711171875\n",
      "57\n",
      "tensor(20981812., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20926.6954921875\n",
      "58\n",
      "tensor(20984106., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20925.2858359375\n",
      "59\n",
      "tensor(20986604., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20917.2951640625\n",
      "60\n",
      "tensor(20982578., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20914.364328125\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "# Training and testing the VAE\n",
    "T=transforms.ToPILImage()\n",
    "codes = dict(μ=list(), logσ2=list(), x=list())\n",
    "for epoch in range(0, epochs + 1):\n",
    "    # Training\n",
    "    if epoch > 0:  # test untrained net first\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x,y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x=x.view(-1,3,480,720)             \n",
    "            y=y.view(-1,4,480,720)\n",
    "            x=torch.div(x,255)\n",
    "            y=torch.div(y,255)\n",
    "            y_bar=model(x)\n",
    "            loss = loss_function(y_bar, y)\n",
    "            train_loss += loss\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "\n",
    "    # Testing\n",
    "        print(train_loss)\n",
    "        wandb.log({\"train_loss\":train_loss /len(train_loader.dataset)})\n",
    "        means, logvars, labels = list(), list(), list()\n",
    "        if epoch%10==0:\n",
    "            torch.save({'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': train_loss,}, \n",
    "                       \"./Weights/resnet_unet.pt\")\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        counter=0\n",
    "        for x,y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x=x.view(-1,3,480,720)\n",
    "            y=y.view(-1,4,480,720)\n",
    "            x=torch.div(x,255)\n",
    "            y=torch.div(y,255)\n",
    "            # ===================forward=====================\n",
    "            ỹ = model(x)\n",
    "            image_y = ỹ[0,:,:,:]\n",
    "            image_x = x[0,:,:,:]\n",
    "            image_y=T(image_y)\n",
    "            image_x=T(image_x)\n",
    "            imgag_y.save(\"./outputs/pred_\"+counter+\"_\"+epoch)\n",
    "            image_x.save(\"./outputs/input\"+counter+\"_\"+epoch)\n",
    "            loss = loss_function(ỹ, y)\n",
    "            test_loss+=loss.item()\n",
    "            counter++;\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(test_loss)\n",
    "    wandb.log({\"test_loss\":test_loss})\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAsyU8rHEAOC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbAfCjL7DoeU"
   },
   "outputs": [],
   "source": [
    "# test_loader=MyDataset(\"./dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp =np.array(Image.open(\"./Datasets/Input/Echendens-LHS_09620.png_6.png\"), dtype = float)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tem = torch.from_numpy(temp).view(-1,3,480,720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tem=tem.to(device,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans=(model(tem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans=(ans[0]*255).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=Image.frtomarray(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOLhjKMsR0xeixlklI73UC8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd4ee977a2a01a9298e92263942feb121ec1e4b1a10d0de0d8efe4cdce6a10eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
